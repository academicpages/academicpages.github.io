<!DOCTYPE html>
<html lang="en">
<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-146712418-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-146712418-1');
</script>

	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

	<title>Lensless Learning</title>

	<!-- Bootstrap -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>

	<link href="styles/minimal.css" rel="stylesheet">
</head>

<body>

<!-- Navigation bar -->
<nav class="navbar navbar-default navbar-fixed-top">
	<div class="container-nav">
		<div class="container-fluid">
    		<ul class="nav navbar-nav">
      			<li class="nav-item active"><a href="index.html">Home</a></li>
      			<li class="nav-item"><a href="https://opg.optica.org/ao/abstract.cfm?uri=ao-61-14-4177">Paper</a></li>
    		</ul>
      	</div>
    </div>
</nav>

<div class="container">

	<div class="row">
		<h1><b>Text detection and recognition based on a lensless imaging system</b></h1>
		<h5><b> Yinger Zhang, Zhouyi Wu, Peiying Lin, Yuting Wu, Lusong Wei, Zhengjie Huang, and Jiangtao Huangfu </b></h5>
		<br />
		<img class="center" src="image/pro_text_framework.jpg" style="width:600px">
	</div>


	<div class="row">
		<h3><b>Abstract</b></h3>
		<p>Mask-based lensless imagers offer smaller form factors and lighter weights than
traditional lensed cameras. In these imagers, the sensor does not directly record the image of the
scene; rather, a computational algorithm reconstructs it. Typically, mask-based lensless imagers
use a model-based approach that suffers from long compute times and a heavy reliance on both
system calibration and heuristically chosen denoisers. In this work, we address these limitations
using a bounded-compute, trainable neural network to reconstruct the image. We leverage our
knowledge of the physical system by unrolling a traditional model-based optimization algorithm,
then use experimentally gathered ground-truth data to optimize the algorithm parameters. The
result is then fed into an optional denoiser, which is jointly trained along with the unrolled
network. As compared to traditional methods, our architecture achieves better perceptual image
quality and runs 20Ã— faster, enabling interactive previewing of the scene. We explore a spectrum
between model-based and deep learning methods, showing the benefits of using an intermediate
approach. Finally, we test our network on images taken in the wild with a prototype mask-based
camera, demonstrating that our network generalizes to natural images.</p>
	</div>

	<div class="row">
		<h3><b>Resources</b></h3>
		<ul>
			<li>Open source code on <b><a href="https://github.com/Waller-Lab/LenslessLearning">GitHub</a></b></li>
			<li>Open access PDF <b><a href="https://www.osapublishing.org/oe/abstract.cfm?uri=oe-27-20-28075">here</a></b></li>
			<li>Original DiffuserCam and Build-your-own <b><a href="https://waller-lab.github.io/DiffuserCam/">tutorial</a></b>
			<li><b><a href="gallery.html">Gallery</a></b> of learned reconstructions</li>
			<li>Open source <b><a href="dataset.html">Dataset</a></b> of aligned lensless and lensed images </li>
		</ul>
	</div>



</div>
<nav class="navbar navbar-default">
</nav>

</body>
</html>