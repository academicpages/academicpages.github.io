
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>FlatNet</title>

    <meta name="description" content="FlatNet">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--FACEBOOK-->
    <meta property="og:image" content="img/twitter-card.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1024">
    <meta property="og:image:height" content="512">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://siddiquesalman.github.io/flatnet/" />
    <meta property="og:title" content="FlatNet" />
    <meta property="og:description"
        content="Project page for FlatNet: Towards Photorealistic Scene Reconstruction from Lensless Measurements." />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="https://siddiquesalman.github.io/flatnet/" />
    <meta name="twitter:title" content="FlatNet" />
    <meta name="twitter:description"
        content="Project page for FlatNet: Towards Photorealistic Scene Reconstruction from Lensless Measurements." />
    <meta name="twitter:image" content="https://siddiquesalman.github.io/flatnet/img/twitter-card.jpg" />

    <!-- FAVICONS -->
    <link rel="apple-touch-icon-precomposed" sizes="57x57"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon-precomposed" sizes="114x114"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon-precomposed" sizes="72x72"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon-precomposed" sizes="60x60"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon-precomposed" sizes="120x120"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon-precomposed" sizes="76x76"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon-precomposed" sizes="152x152"
        href="https://siddiquesalman.github.io/flatnet/favicons/apple-touch-icon-152x152.png" />
    <link rel="icon" type="image/png" href="https://siddiquesalman.github.io/flatnet/favicons/favicon-196x196.png"
        sizes="196x196" />
    <link rel="icon" type="image/png" href="https://siddiquesalman.github.io/flatnet/favicons/favicon-96x96.png"
        sizes="96x96" />
    <link rel="icon" type="image/png" href="https://siddiquesalman.github.io/flatnet/favicons/favicon-32x32.png"
        sizes="32x32" />
    <link rel="icon" type="image/png" href="https://siddiquesalman.github.io/flatnet/favicons/favicon-16x16.png"
        sizes="16x16" />
    <link rel="icon" type="image/png" href="https://siddiquesalman.github.io/flatnet/favicons/favicon-128.png"
        sizes="128x128" />
    <meta name="application-name" content="FlatNet" />
    <meta name="msapplication-TileColor" content="#FFFFFF" />
    <meta name="msapplication-TileImage"
        content="https://siddiquesalman.github.io/flatnet/favicons/mstile-144x144.png" />
    <meta name="msapplication-square70x70logo"
        content="https://siddiquesalman.github.io/flatnet/favicons/mstile-70x70.png" />
    <meta name="msapplication-square150x150logo"
        content="https://siddiquesalman.github.io/flatnet/favicons/mstile-150x150.png" />
    <meta name="msapplication-wide310x150logo"
        content="https://siddiquesalman.github.io/flatnet/favicons/mstile-310x150.png" />
    <meta name="msapplication-square310x310logo"
        content="https://siddiquesalman.github.io/flatnet/favicons/mstile-310x310.png" />


    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5H2C4DFSMD"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-5H2C4DFSMD');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Text detection and recognition based on  <br>
                a lensless imaging system</br>
                <small>
                    Applied Optics
                </small>
            </h2>

        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>                        
                        Yinger Zhang    
                    </li>
                    <li>
                        Zhouyi Wu
                    </li>
                    <li>
                        Peiying Lin
                    </li>
                    <li>
                        Jiangtao Huangfu
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-6 col-md-offset-3 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://opg.optica.org/ao/abstract.cfm?uri=ao-61-14-4177">
                            
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>



                </ul>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="image/pro_text_framework.jpg" class="img-responsive" alt="overview"><br>
                    <p class="text-justify">
                        Lensless cameras are characterized by several advantages (e.g., miniaturization, ease of manufacture, and low cost) as compared with conventional cameras. However, they have not been extensively employed due to their poor image clarity and low image resolution, especially for tasks that have high requirements on image quality and details such as text detection and text recognition. To address the problem, a framework of deep-learning-based pipeline structure was built to recognize text with three steps from raw data captured by employing lensless cameras. This pipeline structure consisted of the lensless imaging model U-Net, the text detection model connectionist text proposal network (CTPN), and the text recognition model convolutional recurrent neural network (CRNN). Compared with the method focusing only on image reconstruction, U-Net in the pipeline was able to supplement the imaging details by enhancing factors related to character categories in the reconstruction process, so the textual information can be more effectively detected and recognized by CTPN and CRNN with fewer artifacts and high-clarity reconstructed lensless images. By performing experiments on datasets of different complexities, the applicability to text detection and recognition on lensless cameras was verified. This study reasonably demonstrates text detection and recognition tasks in the lensless camera system, and develops a basic method for novel applications.
                        <br>
                    </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Hardware
                </h3>
                

                <p align="center">
                <image class="center" src="image/pro_text_hardware.png"   width="500"  alt="overview" /><br>
                </p>
                   
                
                
                <br /> <b>Forward Model</b> consists of two stages: (1) Matrix-vector multiplication
                (2) Convolutional Model<br>
                <br />
                <center> <font size=4><b>b=Hv </b>   </font></center> <br>
                <p align="center">
                </br><image class="center" src="image/pro_text_thoery.PNG" width="400"  alt="theroy" /><br>
                </br><image class="center" src="image/pro_text_equation.PNG" width="300"  alt="theroy" /><br>
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Result
                </h3>

                <br> <b>Reconstruction results from ADMM and CRNN</b>

                <p align="center">
                </br><image class="center" src="image/pro_text_admm_cnn.PNG" width="500"  alt="admm&cnn" /><br>
                </p>

                <b>Reconstruction results of NCD and IIIT5K </b>

                <p align="center">
                </br><image class="center" src="image/pro_text_size.PNG" width="550"  alt="admm&cnn" /><br>

                </p>

                
            </div>
        </div>

        

        

       






    <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Key Contributions
                </h3>
                <br />
                <ul>
                    <li>We propose an efficient implementation for the learnable intermediate stage of a general
                        lensless model. In our <a href=https://siddiquesalman.github.io/flatcam_iccv.html>prior
                            work</a>, we shown this for the separable lensless model. Here
                        we non-trivially extend it to the general lensless case.</li>

                    <figure>
                        <image src="img/fig_7_sim.jpg" class="img-responsive" alt="overview">
                            <figcaption><b>Some simulated outputs.</b> Notice how closely the simulated measurements
                                resemble real ones.
                            </figcaption>
                    </figure>

                    <li>We verify the robustness of the proposed learnable intermediate mapping for the non-separable
                        lensless model on challenging scenarios where the lensless system does not follow a full
                        convolutional assumption.</li>

                    <li>We propose an initialization scheme for the non- separable lensless model that doesnâ€™t require
                        explicit PSF calibration.</li>

                    <li>Similar to the display and direct captured measurements collected using the separable mask
                        <i><a href=https://intra.ece.ucr.edu/~sasif/papers/2015_AASVR_flatcam_iccv.pdf>FlatCam</a></i>
                        and described in our <a href=https://siddiquesalman.github.io/flatcam_iccv.html>previous
                            work</a>, we collect corresponding datasets for the
                        non-separable mask <i><a href=https://ieeexplore.ieee.org/document/9076617>PhlatCam</a></i>.
                    </li>

                    <br>

                    <figure>
                        <image src="img/dataset3.jpg" class="img-responsive" alt="overview">
                            <figcaption><b><br>Some simulated outputs.</b> Notice how closely the simulated measurements
                                resemble real ones.
                            </figcaption>
                    </figure>

                    <li>We also collect a dataset of unconstrained indoor lensless measurements paired with
                        corresponding unaligned webcam images which is finally used to finetune our proposed
                        <b>FlatNet</b> to
                        robustly deal with unconstrained real-world scenes.</li>

                    <li>Our method outperforms previous traditional and deep learning based lensless reconstruction
                        methods.</li>
                </ul>
            </div>
        </div> -->




</body>

</html>