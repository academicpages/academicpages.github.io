---
title: "ML-CASCADE: A Machine Learning and Cloud Computing-based Tool for Rapid and Automated Mapping of Landslides using Earth Observation Data"
collection: publications
permalink: /publication/ML-CASCADE
date: 
venue: 
---
[Github codebase](https://github.com/der-knight/ML-CASCADE)  
[App Link](https://hydrosense.users.earthengine.app/view/ml-cascade)  

![image](https://github.com/der-knight/ML-CASCADE/blob/main/Images/Landslide%20Tool.jpg)

<b>Abstract</b>  
<b>Landslides pose a significant threat to humans as well as the environment. Rapid and precise mapping of landslide extent is necessary for understanding their spatial distribution, assessing susceptibility, and developing early warning systems. Traditional landslide mapping methods rely on labor-intensive field studies and manual mapping using high-resolution imagery, which are both costly and time-consuming. While existing machine learning-based automated mapping methods exist, they have limited transferability due to low availability of training data and the inability to handle out-of-distribution scenarios. This study introduces ML-CASCADE, a user-friendly open-source tool designed for real-time landslide mapping. It is a semi-automated tool that requires the user to create landslide and non-landslide samples using pre- and post-landslide Sentinel-2 imagery to train a machine learning model. The model training features include Sentinel-2 data, terrain data, vegetation indices, and bare soil index. ML-CASCADE is developed as an easy-to-use application on top of Google Earth Engine and supports both pixel and object-based classification methods. We validate the landslide extent developed using ML-CASCADE with independent expert-developed inventories. ML-CASCADE is not only able to identify the landslide extent accurately but can also map a complex cluster of landslides within 5 minutes and a simple landslide within 2 minutes. Due to its ease of use, speed, and accuracy, ML-CASCADE will serve as a critical operational asset for landslide risk management</b>


