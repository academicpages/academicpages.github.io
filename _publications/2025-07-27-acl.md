---
title: "RUBRIC-MQM : Span-Level LLM-as-judge in Machine Translation For High-End Models"
collection: publications
category: conferences
permalink: /publication/2025/07/post-acl/
excerpt: 'Referred to as LLM-as-judge, a generative large language model (LLM) has demonstrated considerable efficacy as an evaluator in various tasks, including Machine Translation (LAJ-MT) by predicting scores or identifying error types for individual sentences. However, its dependability in practical application has yet to be demonstrated, as there is only an approximated match due to the task’s open-ended nature. To address this problem, we introduce a straightforward and novel meta-evaluation strategy PromptCUE and evaluate cutting-edge LAJ-MT models such as GEMBA-MQM. We identify their fundamental deficits, including certain label biases and the inability to assess near-perfect translations.To improve reliability, we investigate more trustworthy and less biased models using multidimensional prompt engineering. Our findings indicate that the combination of span-level error quantification and a rubric-style prompt tailored to the characteristics of LLMs has efficiently addressed the majority of the challenges current LAJ-MT models face. Furthermore, it demonstrates a considerably enhanced alignment with human values. Accordingly, we present Rubric-MQM, the LAJ-MT for high-end models and an updated version of GEMBA-MQM.'
image: '/images/pub/rmqm_logo.png'
date: 2025-07-27
venue: 'ACL Industry'
codeurl: 'https://github.com/trotacodigos/Rubric-MQM'
paperurl: 'https://aclanthology.org/2025.acl-industry.12.pdf'
bibtexurl: '/files/2025.acl-industry.12.bib'
authors: '<span class="me">Ahrii Kim</span>'
citation: 'Kim, Ahrii. (2025). &quot;RUBRIC-MQM : Span-Level LLM-as-judge in Machine Translation For High-End Models.&quot; <i>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 6: Industry Track)</i>, pages 147–165, Vienna, Austria. Association for Computational Linguistics.'
---