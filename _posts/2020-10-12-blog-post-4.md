---
title: 'Privacy papers in NeurIPS 2020'
date: 2020-10-12
permalink: /posts/2020/10/privacy-neurips20/
tags:
  - Privacy
  - Machine Learning
---


I have curated and am beginning to read NeurIPS '20 [papers](https://nips.cc/Conferences/2020/AcceptedPapersInitial) related to privacy.  The list will be constantly updated with the paper summaries. Stay tuned!  
*Note that I wrote a simple script to scrape the ArXiv links to the paper and the links may not be accurate.*

|*Title*  |*Summary*  |
|---|---|
|[A Simple and Practical Algorithm for Private Multivariate Mean and Covariance Estimation](https://arxiv.org/abs/2006.06618)||
|[The Discrete Gaussian for Differential Privacy](https://arxiv.org/abs/2004.00010)||
|[Private Identity Testing for High-Dimensional Distributions](https://arxiv.org/abs/1905.11947)|
|[Differentially-Private Federated Contextual Bandits](http://web.mit.edu/dubeya/www/files/dp_linucb_20.pdf)||
|Permute-and-Flip: A new mechanism for differentially-private selection||
|[Auditing Differentially Private Machine Learning: How Private is Private SGD?](https://arxiv.org/abs/2006.07709)|Introduce a method to measure the emperically achievable value of epsilon. Also introduce an algorithm of poisoning that is effective against SGD clipping|
|[AutoPrivacy: Automated Layer-wise Parameter Selection for Secure Neural Network Inference](https://arxiv.org/abs/2006.04219)||
|[Adversarially Robust Streaming Algorithms via Differential Privacy](https://arxiv.org/abs/2004.05975)||
|[Locally Differentially Private (Contextual) Bandits Learning](https://arxiv.org/abs/2006.00701)||
|[Locally private non-asymptotic testing of discrete distributions is faster using interactive mechanisms](https://arxiv.org/abs/2005.12601)||
|[On the Equivalence between Online and Private Learnability beyond Binary Classification](https://arxiv.org/abs/2006.01980)||
|A Scalable Approach for Privacy-Preserving Collaborative Machine Learning||
|[Private Learning of Halfspaces: Simplifying the Construction and Reducing the Sample Complexity](https://arxiv.org/abs/2004.07839)||
|[Synthetic Data Generators -- Sequential and Private](https://arxiv.org/pdf/1902.03468.pdf)||
|Smoothly Bounding User Contributions in Differential Privacy||
|[Learning from Mixtures of Private and Public Populations](https://arxiv.org/abs/2008.00331)||
|[Smoothed Analysis of Online and Differentially Private Learning](https://arxiv.org/abs/2006.10129)||
|[Privacy Amplification via Random Check-Ins](https://arxiv.org/abs/2007.06605)|Try to solve the problem of determining the population size when using central DP in FL|
|[The Flajolet-Martin Sketch Itself Preserves Differential Privacy: Private Counting with Minimal Space](https://arxiv.org/pdf/1508.06110)||
|[Understanding Gradient Clipping in Private SGD: A Geometric Perspective](https://arxiv.org/abs/2006.15429)||
|[Differentially Private Clustering: Tight Approximation Ratios](https://arxiv.org/abs/2008.08007)||
|[A Computational Separation between Private Learning and Online Learning](http://arxiv.org/abs/2007.05665)||
|[Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms](https://arxiv.org/abs/2005.10630)||
|Improving Sparse Vector Technique with Renyi Differential Privacy||
|[Breaking the Communication-Privacy-Accuracy Trilemma](https://arxiv.org/abs/2007.11707)||
|[Inverting Gradients - How easy is it to break privacy in federated learning?](https://arxiv.org/abs/2003.14053)| Show that FL without DP is vulnerable to reconstruction attack, at least in Computer Vision|
|[GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators](https://arxiv.org/abs/2006.08265)|sanitize selectively (only the generator) and bounding sensitivity with wasserstein distance instead of clipping.|
|[Optimal Private Median Estimation under Minimal Distributional Assumptions](https://arxiv.org/pdf/2002.08774)||
|[Towards practical differentially private causal graph discovery](https://arxiv.org/abs/2006.08598)||
|[Learning discrete distributions: user vs item-level privacy](https://arxiv.org/abs/2007.13660)||
|Faster Differentially Private Samplers via RÃ©nyi Divergence Analysis of Discretized Langevin MCMC||
|[CryptoNAS: Private Inference on a ReLU Budget](https://arxiv.org/abs/2006.08733)||
|[A Simple and Nearly Optimal Analysis of Privacy Amplification by Shuffling](https://arxiv.org/abs/2012.12803)||
