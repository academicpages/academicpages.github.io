---
title: "Patch-adaptive Transformation Blending for One-shot Retouching"
excerpt: "<img src='/images/architecture.png'><br/>This project introduces a novel photo retouching technique based on a single before-after example pair."
collection: projects
---

<!-- <br/><img src="/images/RetouchingStyles_cropped-1.png" alt="drawing" width="400"/> -->

<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>TBMLP</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://faziletgokbudak.github.io/one-shot/img/architecture.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="600">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://faziletgokbudak.github.io/one-shot">
    <meta property="og:title" content="Patch-adaptive Transformation Blending for One-shot Photo Retouching">
    <meta property="og:description" content="Our technique automatically retouches photos by learning the desired edits from one example <i>before-after pair</i> (as indicated in images or shown in small boxes). The learned retouches accurately capture edits in intricate details, such as skin textures as shown in input-retouched pairs.">

<!-- 
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields">
    <meta name="twitter:description" content="Neural Radiance Fields (NeRF) is a popular view synthesis technique that represents a scene as a continuous volumetric function, parameterized by multilayer perceptrons that provide the volume density and view-dependent emitted radiance at each location. While NeRF-based techniques excel at representing fine geometric structures with smoothly varying view-dependent appearance, they often fail to accurately capture and reproduce the appearance of glossy surfaces. We address this limitation by introducing Ref-NeRF, which replaces NeRF's parameterization of view-dependent outgoing radiance with a representation of reflected radiance and structures this function using a collection of spatially-varying scene properties. We show that together with a regularizer on normal vectors, our model significantly improves the realism and accuracy of specular reflections. Furthermore, we show that our model's internal representation of outgoing radiance is interpretable and useful for scene editing.">
    <meta name="twitter:image" content="https://dorverbin.github.io/refnerf/img/refnerf_titlecard.jpg">
 -->
    <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
<!--             <h2 class="col-md-12 text-center" id="title">
                Patch-adaptive Transformation Blending <br> for One-shot Photo Retouching <br>
            </h2> -->
        </div>
    </div>
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script>
    <div class="container" id="main">


	<script
	  defer
	  src="https://unpkg.com/img-comparison-slider@7/dist/index.js"
	></script>
	<link
	  rel="stylesheet"
	  href="https://unpkg.com/img-comparison-slider@7/dist/styles.css"
	/>

	
	
        <div class="row">
            <div class="col-md-8 col-md-offset-2">

                
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
				<img-comparison-slider>
				  <img slot="first" src="/images/68909.png" width="100%" ; height: auto ;style="margin:auto;"/>
				  <img slot="second" src="/images/PT_makeup2_test6_256_with_var.png" width="100%" ; height: auto; style="margin:auto;"/>
				</img-comparison-slider>                                
                                <canvas height=0 class="videoMerge" id="water2Merge"></canvas>
                        </td>
                        <td align="left" valign="top" width="50%">
				<img-comparison-slider>
				  <img slot="first" src="/images/test1.png" width="100%" ; height: auto; style="margin:auto;"/>
				  <img slot="second" src="/images/PT_sharpen_test1_256_with_var.png" width="100%" ; height: auto; style="margin:auto;"/>
				</img-comparison-slider>                                
                                <canvas height=0 class="videoMerge" id="water3Merge"></canvas>
                        </td>
                    </tr>
                </table>
		<div class="text-justify">
			Our technique learns different retouching styles from a single example before-after image pair, which can be found in Additional Results (Left: Top row, Right: Bottom row). 
		</div>

            </div>
        </div>

<!-- 	    
	    
	 
	<img-comparison-slider>
	  <img slot="first" src="/images/68909.png" width="400" height="400" />
	  <img slot="second" src="/images/PT_makeup2_test6_256_with_var.png" width="400" height="400" />
	</img-comparison-slider>
	<img-comparison-slider>
	  <img slot="first" src="/images/test1.png" width="400" height="400" />
	  <img slot="second" src="/images/PT_sharpen_test1_256_with_var.png" width="400" height="400" />
	</img-comparison-slider>
	  -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
Photo retouching is, in general, a difficult task for novice users as it requires expert knowledge and advanced tools. Photographers often spend a great deal of time generating high-quality retouched photos with intricate details. In this work, we introduce a learning-based technique to automatically retouch details of an input image based on a single pair of before and after example images. Our approach provides detailed retouches without manual effort or a large dataset by learning a different map per frequency level. By decomposing before and after images into different frequency levels based on multiscale image analysis, we achieve a higher expressive power of the model. To further increase the capacity of our model, we blend multiple transformation matrices with scalar weights learned by a multilayer perceptron (MLP) block. Previous work shows that, instead of predicting an edited image directly from an input image, learning a transformation is, in general, more efficient and easier. Therefore, our technique learns transformation matrices and computes their weighted sum to define maps. Since the weights are patch-adaptive thanks to the MLP block, our map representation becomes spatially varying, capturing retouching edits even in complex details.                    </p>
            </div>
        </div>
<!-- 	    max-height: 450px; -->
	    
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <image src="/images/architecture.png" class="img-responsive" alt="overview" style="margin:auto;">
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Transformation Blending
                </h3>
                <div class="text-justify">
<!-- 			<i>Integrated Directional Encoding</i> -->
		    A novel learning-based image mapping technique in patch space designed to capture highly detailed retouching styles. Inspired by artistic retouching pipelines, our approach provides accurate representations of intricate details while preserving the semantics of the input image. With the help of prior knowledge about artistic retouching pipelines, our map representation can generalize well to new images with different structures.                </div>
            </div>
        </div>
		
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Patch-adaptive Weights
                </h3>
                <div class="text-justify">
		   Transformations are tuned based on patch values and hence achieve local adjustments. Weights learned by the MLP block blend various transformation matrices. Our approach helps us mimic local edit tools of professionals, such as a brush tool or local filters.                 </div>
        </div>
		
<!--         <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                   Nuances of Different Retouching Styles
                </h3>
        	<image src="/images/RetouchingStyles_cropped-1.png" class="img-responsive" alt="overview" style="margin:auto;">
	    </div>
        </div> -->
		

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Additional Results
                </h3>
	
<!-- 		<image src="/images/AdditionalResults-1.png" class="img-responsive" alt="overview"  style="margin:auto;">
 -->
            </div>
        </div>
<!-- 	<div class="text-justify">
		Our technique automatically retouches photos by learning the desired edits from one example <i>before-after pair</i> (as indicated in images or shown in small boxes). The learned retouches accurately capture edits in intricate details, such as skin textures as shown in input-retouched pairs.
 -->
<!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Additional Results
                </h3>
                <div class="text-justify">
            </div>
        </div> -->
		
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    
                </h3>
        	<image src="/images/AdditionalResults2.png" class="img-responsive" alt="overview"  style="margin:auto;">
	                <div class="text-justify">
			    Our technique automatically retouches photos by learning the desired edits from one example <i>before-after pair</i> (as indicated in images or shown in small boxes). The learned retouches accurately capture edits in intricate details, such as skin textures as shown in input-retouched pairs.
			</div>
	    </div>
        </div>
<!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="https://dorverbin.github.io/refnerf/">Ref-NeRF</a>.
                </p>
            </div>
        </div> -->
    </div>

    
<!--         <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
		</div>
	    </div>
	</div>
</body></html> -->

