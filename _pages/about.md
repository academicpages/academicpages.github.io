---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<html>
<head>
<style>
a:link {
  color: RoyalBlue;
  background-color: transparent;
  text-decoration: none;
}

a:visited {
  color: SteelBlue;
  background-color: transparent;
  text-decoration: none;
}

a:hover {
  color: RoyalBlue;
  background-color: transparent;
  text-decoration: underline;
}

a:active {
  color: DarkRed;
  background-color: transparent;
  text-decoration: underline;
}
</style>  
</head>  
  
<body>
<p align="justify" vspace = "-0px" width="160px"> I am a postdoctoral researcher at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-york/">Microsoft Research New York City</a>. I obtained my PhD from the department of <a href="https://www.csa.iisc.ac.in">Computer Science</a>, <a href="https://iisc.ac.in/">Indian Institute of Science, Bangalore</a>, advised by <a href="https://ece.iisc.ac.in/~aditya/">Aditya Gopalan</a> and <a href="https://eecs.iisc.ac.in/people/chiranjib-bhattacharyya/">Chiranjib Bhattacharyya</a>. I was fortunate to intern at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/">Microsoft Research, Bangalore</a>, <a href="https://www.inria.fr/en/centre-inria-de-paris">Inria, Paris</a>, and <a href="https://ai.google/">Google AI, Mountain View</a>.</p> 
<!-- Before that, I was a CS undergrad at [IIEST, Shibpur](https://www.iiests.ac.in/). -->

<b><font color="SteelBlue">Research interests:</font></b> Bandits, Reinforcement Learning, Optimization, Learning theory, Algorithms. 

<p align="justify"> My current research focuses on developing large-scale robust algorithms for sequential decision-making tasks under restricted feedback, for example, preference information, click data, proxy rewards, partial ranking, etc. Some of my other recent ventures also include handling non-stationarity in contextual environments, differential privacy, multiplayer games, online convex optimization. Broadly, I am fascinated by the scopes of learning from unconventional partial monitoring feedback and the gaps between theory and practice.</p>
  
<a href="https://aadirupa.github.io#selected_publications">[Selected Papers]</a> &nbsp;
<a href="https://aadirupa.github.io/publications#full_publications" target="_blank">[Full List]</a> &nbsp;
<a href="https://scholar.google.co.in/citations?user=7a49tQYAAAAJ&hl=en" target="_blank">[Google Scholar]</a> &nbsp;
<a href="https://arxiv.org/find/all/1/au:+saha_aadirupa/0/1/0/all/0/1" target="_blank">[arXiv]</a>  

  <br>
<!-- <hr style="color:black;">  -->
  <br>
 <p align="justify" vspace = "0px" width="160px"><b><font color="SteelBlue">Collaborators.</font></b> I have been really fortunate to be able to work with some of the amazing research minds: 
  <a href="https://www.csa.iisc.ac.in/~chiru/" target="_blank">Chiranjib Bhattacharyya</a>,
   <a href="https://www.microsoft.com/en-us/research/people/sadevlin/" target="_blank">Sam Devlin</a>, 
   <a href="https://sites.google.com/view/yonathan-efroni/home" target="_blank">Yonathan Efroni</a>,
   <a href="http://pierre.gaillard.me/" target="_blank">Pierre Gaillard</a>,
   <a href="https://ece.iisc.ac.in/~aditya/" target="_blank">Aditya Gopalan</a>,
   <a href="https://scholar.google.co.in/citations?user=Nt-tK2UAAAAJ&hl=en" target="_blank">Shubham Gupta</a>,
   <a href="https://www.microsoft.com/en-us/research/people/kahofman/" target="_blank">Katja Hofmann</a>,
   <a href="https://www.prateekjain.org/" target="_blank">Prateek Jain</a>,
   <a href="https://sumeetsk.github.io/" target="_blank">Sumeet Katariya</a>,
   <a href="https://tomerkoren.github.io/" target="_blank">Tomer Koren</a>,
   <a href="https://people.cs.umass.edu/~akshay/" target="_blank">Akshay Krishnamurthy</a>,
   <a href="https://webee.technion.ac.il/Sites/People/shie/" target="_blank">Shie Mannor</a>,
   <a href="https://www.tau.ac.il/~mansour/" target="_blank">Yishay Mansour</a>,
    <a href="https://scholar.google.co.il/citations?user=pX2zzp0AAAAJ&hl=en" target="_blank">Nadav Merlis</a>,
   <a href="https://www.microsoft.com/en-us/research/people/nagarajn/" target="_blank">Nagarajan Natarajan</a>,
   <a href="https://praneethnetrapalli.org/" target="_blank">Praneeth Netrapalli</a>,
   <a href="https://scholar.google.ca/citations?user=izPG6OEAAAAJ&hl=en" target="_blank">Rakesh Shivanna</a>,
   <a href="https://misovalko.github.io/" target="_blank">Michal Valko</a>
  (in alphabetical order).</p>
<!--[Nadav Merlis]()-->
  
<h2 style="color:SteelBlue;"><a id="selected_publications">Selected Papers:</a></h2>

<ul style="margin:1;padding:1" vspace = "-0px">
  <li>  <b>Dueling Bandits with Adversarial Sleeping</b> <a href="https://arxiv.org/abs/2107.02274" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard
  <br>  (To appear) In Neural Information Processing Systems, NeurIPS 2021</li>

  <li>  <b>Optimal Algorithms for Stochastic Contextual Dueling Bandits</b>
  <br>  Aadirupa Saha
  <br>  (To appear) In Neural Information Processing Systems, NeurIPS 2021</li>
  
  <li>  <a href="http://proceedings.mlr.press/v139/saha21b.html" target="_blank"><b>Dueling Convex Optimization</b></a>
  <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour
  <br>  In International Conference on Machine Learning, ICML 2021</li>
  
  <li>  <a href="http://proceedings.mlr.press/v139/saha21a.html" target="_blank"><b>Adversarial Dueling Bandits</b></a> <a href="https://arxiv.org/abs/2010.14563" target="_blank"> [Arxiv Version]</a>
 <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour
  <br>  In International Conference on Machine Learning, ICML 2021</li>
    
  <li> <a href="http://proceedings.mlr.press/v139/saha21c.html" target="_blank"><b>Optimal Regret Algorithm for Pseudo-1d Bandit Convex Optimization</b></a> <a href="https://arxiv.org/abs/2102.07387" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Nagarajan Natarajan, Praneeth Netrapalli, Prateek Jain
  <br> In International Conference on Machine Learning, ICML 2021</li>
    
  <li>  <a href="https://proceedings.mlr.press/v119/saha20b.html" target="_blank" LINK="red"><b>From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce Model</b></a> <a href="https://arxiv.org/abs/1903.00558" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Machine Learning, ICML 2020</li>
    
  <li>  <a href="https://proceedings.mlr.press/v108/aadirupa-saha20a.html" target="_blank"><b>Best-item Learning in Random Utility Models with Subset Choices</b></a> <a href="https://arxiv.org/abs/2002.07994" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2020</li>
    
  <li>  <a href="http://papers.nips.cc/paper/8384-combinatorial-bandits-with-relative-feedback" target="_blank"><b>Combinatorial Bandits with Relative Feedback</b></a><a href="https://arxiv.org/abs/1903.00543" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In Neural Information Processing Systems, NeurIPS 2019</li>
    
  <li>  <a href="http://proceedings.mlr.press/v98/saha19a.html" target="_blank"><b>PAC Battling Bandits in the Plackett-Luce Model</b></a> <a href="https://arxiv.org/abs/1808.04008" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In Algorithmic Learning Theory, ALT 2019</li>
</ul>
 
<hr style="color:black;"> 
 
</body>
</html>

<!--Email: firstname.lastname @ microsoft.com-->

