---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Postdoctoral Associate at the University of Notre Dame, where I collaborate on cutting-edge research at the intersection of artificial intelligence, explainability, and social good. My work focuses on advancing medical equality in low- and middle-income countries through the application of AI tools, including Large Language Models (LLMs), and enhancing the fairness and transparency of contemporary AI systems.

Research Interests
======
My research is centered on **Responsible AI** and **Security Techniques**, with a particular emphasis on:
- **Explainable Machine Learning**: Developing methods to make AI models more interpretable and transparent
- **Fairness in AI**: Ensuring equitable outcomes across different populations and contexts
- **Adversarial Robustness**: Building resilient AI systems that can withstand malicious attacks
- **Anomaly Detection**: Creating intelligent systems for identifying unusual patterns and behaviors
- **Large Language Models**: Investigating the interpretability and explainability of generative AI

I am passionate about advancing innovation through research that bridges the gap between academia and industry, with the ultimate goal of developing AI solutions that are not only powerful but also trustworthy and beneficial to society.

Background
======
I earned my Ph.D. in Computer Science from Wayne State University in 2022, where my dissertation focused on "Interpretable Machine Learning and Applications." Following my doctorate, I worked as an Applied Scientist at AntGroup Inc. in Shanghai, where I contributed to developing the Ant Model Risk Evaluation system and designed security solutions for the Alipay ecosystem.

Current Projects
======
I am currently working on developing a comprehensive framework to enhance the interpretability of generative large language models, such as Llama3. This project aims to create clear insights into the decision-making processes of these models, thereby improving their transparency and practical usability in real-world applications.

Recent Updates
======
I'm excited to share that our paper "Fast Explanations via Policy Gradient-Optimized Explainer" has been accepted to IJCAI-25! We also have a preprint on "Context Attribution with Multi-Armed Bandit Optimization" available.
