---
permalink: /
title: "Hongpeng Lin"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Welcome! I am a 3rd-year master student of Artificial Intelligence at [Gaoling School of Artificial Intelligence](http://ai.ruc.edu.cn/english), [Renmin University of China](https://www.ruc.edu.cn/en). I'm advised by Prof. [Ruihua Song](https://gsai.ruc.edu.cn/addons/teacher/index/info.html?user_id=0&ruccode=ATNUbVJhBjJRNgY3UDQFMg%3D%3D&ln=en), working on Natural Language Processing (NLP) and Multi-modal Dialogue. Prior to that, I completed my B.S. from School of Computer Science and Technology, [Xidian University](https://en.xidian.edu.cn/).

Email: [hopelin@ruc.edu.cn](mailto:hopelin@ruc.edu.cn) / [CV](https://hopelin99.github.io/assets/CV_hongpenglin.pdf)

## Research Interests
My research interests lie in Natural Language Processing and Multi-modal Understanding, for the purpose of giving machines the ability to perceive, understand, and express like humans.

I have been dedicated to equipping large language models (LLMs) with the capability to process multi-modal information, endowing them with the capacity to perceive the world. Some of my recent projects include addressing QA for long-form videos and exploring vulnerabilities in large language models.


## News
**01/2024** &nbsp;&nbsp;&nbsp;&nbsp; Checkout our new papers on how to [persuade LLMs to jailbreak them](https://chats-lab.github.io/persuasive_jailbreaker/) with a success rate of **92%**.


<video src="https://github.com/CHATS-lab/persuasive_jailbreaker/assets/61967882/3c04d83c-564d-40a5-87e8-423e0d377012" controls="controls" style="max-width: 730px;"></video>



<br>
**08/2023** &nbsp;&nbsp;&nbsp;&nbsp; Our paper "TikTalk" on multi-modal dialogue is accepted by ACM MM 2023!

## Papers

* How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs

  <br>Yi Zeng\*, **Hongpeng Lin\*** (lead authors), Jingwen Zhang, Diyi Yang, Ruoxi Jia*, Weiyan Shi\* (co-supervise)

  arXiv, [Project](https://chats-lab.github.io/persuasive_jailbreaker/) [Paper](https://arxiv.org/abs/2401.06373) [Code](https://github.com/CHATS-lab/persuasive_jailbreaker)

  

* TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World
<br>
**Hongpeng Lin\***, Ludan Ruan\*, Wenke Xia\*, Peiyu Liu, Jingyuan Wen, Yixin Xu, Di Hu, Ruihua Song, Wayne Xin Zhao, Qin Jin, Zhiwu Lu
<br>
*ACM MM 2023(Oral)* &nbsp;&nbsp; [Project](https://ruc-aimind.github.io/projects/TikTalk/) [Paper](https://dl.acm.org/doi/abs/10.1145/3581783.3612425) [Code](https://github.com/RUC-AIMind/TikTalk)


* Analysis on the collection method and simulation algorithm of Chinese speech errors
<br>
Hao Pu, **Hongpeng Lin**, Ruihua Song, Mei Yan
<br>
*CLSW 2022*


## Service

* *Conference reviewer*: EMNLP, ACM MM, CVPR







