---
permalink: /
layout: archive
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a 2nd-year Master student at [Saruwatari & Saito Lab.](https://www.sp.ipc.i.u-tokyo.ac.jp/index-en), [Graduate school of Information Science and Technology](https://www.i.u-tokyo.ac.jp/index_e.shtml), [the University of Tokyo](https://www.u-tokyo.ac.jp/en/index.html), Japan.
My research focuses on the domain of speech and language processing such as speech synthesis, voice conversion, and para/non-linguistic information modeling.
I am especially interested in modeling and generating expressive prosody.
Also, through it, I aim to the development of human-friendly speech agents that can adaptively and naturally communicate with a variety of people.

[æ±äº¬å¤§å­¦](https://www.u-tokyo.ac.jp/ja/index.html) [å¤§å­¦é™¢æƒ…å ±ç†å·¥å­¦ç³»ç ”ç©¶ç§‘](https://www.i.u-tokyo.ac.jp/index.shtml) [ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å­¦å°‚æ”»ç¬¬ä¸€ç ”ç©¶å®¤](https://www.sp.ipc.i.u-tokyo.ac.jp/) ä¿®å£«2å¹´ã®å±±å†…ä¸€è¼ã§ã™ï¼
éŸ³å£°åˆæˆï¼ŒéŸ³å£°å¤‰æ›ï¼Œãƒ‘ãƒ©è¨€èª/éè¨€èªæƒ…å ±ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãªã©ï¼ŒéŸ³å£°è¨€èªæƒ…å ±å‡¦ç†ã®é ˜åŸŸã‚’ä¸­å¿ƒã«ç ”ç©¶ã—ã¦ã„ã¾ã™ï¼
ãã®ä¸­ã§ã‚‚ç‰¹ã«ï¼Œè¡¨ç¾åŠ›è±Šã‹ãªéŸ»å¾‹ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„ç”Ÿæˆã«èˆˆå‘³ã‚’æŒã£ã¦ã„ã¾ã™ï¼
ã¾ãŸï¼Œãã‚Œã‚’é€šã—ã¦ï¼Œæ§˜ã€…ãªäººã¨é©å¿œçš„ã‹ã¤è‡ªç„¶ã«ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã§ãã‚‹ï¼Œãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªéŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ï¼

**Email (university)**: yamauchi-kazuki042 [at] g.ecc.u-tokyo.ac.jp<br>
**Email (personal)**: kyamauchi1023 [at] gmail.com<br>
**Address**: Room #140, Engineering bldg. #6, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan


## Research Interests

- Speech and Language Processing
- Speech Synthesis
- Natural Language Processing
- Deep Learning
- Signal Processing


## Education

- Apr. 2023 - Mar. 2025<br>
**Masterâ€™s Degree in Information Science and Technology**, the University of Tokyo, Japan<br>
Department of Creative Informatics, Graduate School of Information Science and Technology<br>
(æ±äº¬å¤§å­¦ å¤§å­¦é™¢æƒ…å ±ç†å·¥å­¦ç³»ç ”ç©¶ç§‘ å‰µé€ æƒ…å ±å­¦å°‚æ”»)
- Apr. 2019 - Mar. 2023<br>
**Bachelorâ€™s Degree in Engineering**, the University of Tokyo, Japan<br>
Department of Mathematical Engineering and Information Physics, Faculty of Engineering<br>
(æ±äº¬å¤§å­¦ å·¥å­¦éƒ¨ è¨ˆæ•°å·¥å­¦ç§‘)


## Awards & Honours

- Jun. 2024<br>
ğŸ‰ **Best Presentation Award / å„ªç§€ç™ºè¡¨è³** \[[link](https://www.ipsj.or.jp/award/musslp-award1.html)\]<br>
Sound Symposium / éŸ³å­¦ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ 
- Mar. 2024<br>
ğŸ‰ **Ranked 1st in TTS (Acoustic+Vocoder) track** \[[link](https://huggingface.co/spaces/discrete-speech/interspeech2024_discrete_speech_tts_full)\]<br>
Interspeech2024 Speech Processing Using Discrete Speech Unit Challenge
- Mar. 2024<br>
ğŸ‰ **Best Student Presentation Award / å­¦ç”Ÿå„ªç§€ç™ºè¡¨è³** \[[link](https://acoustics.jp/awards/student/)\]<br>
Acoustical Society of Japan, ASJ / æ—¥æœ¬éŸ³éŸ¿å­¦ä¼š
- Mar. 2024<br>
ğŸ‰ **Best Student Poster Award / å­¦ç”Ÿãƒã‚¹ã‚¿ãƒ¼è³** \[[link](https://www.ieice.org/iss/sp/jpn/special/sp-poster-prize.html)\]<br>
IEICE Speech Committee / é›»å­æƒ…å ±é€šä¿¡å­¦ä¼š éŸ³å£°ç ”ç©¶ä¼š


<!-- ## Grants & Scholarships -->


## Research and Work Experiences

- Mar. 2023 -<br>
**CoeFont Co.,Ltd. / æ ªå¼ä¼šç¤¾CoeFont**, Part-Time AI Researcher<br>
Researching on speech processing.
- Aug. 2023 - Sep. 2023<br>
**NTT Human Informatics Laboratories / NTTäººé–“æƒ…å ±ç ”ç©¶æ‰€**, Research Internship<br>
Researched on speaking style captioning.
- Sep. 2021 - Mar. 2024<br>
**Nagase Brothers Inc. / æ ªå¼ä¼šç¤¾ãƒŠã‚¬ã‚»**, Part-Time AI Researcher & Engineer<br>
Worked on natural language processing and developed web application.


<!-- ## Volunteer Works:

- Apr. 2024 - <br>
**Acoustical Society of Japan (ASJ) Students and Young Researchers Forum, Organizing member / æ—¥æœ¬éŸ³éŸ¿å­¦ä¼š å­¦ç”Ÿãƒ»è‹¥æ‰‹ãƒ•ã‚©ãƒ¼ãƒ©ãƒ  å¹¹äº‹ä¼šå“¡**  -->


## Other Experiences

- Apr. 2024<br>
**Invited to Google Research Talk, Google Tokyo, Japan**<br>
Talked about our technical report for Interspeech2024 Speech Processing Using Discrete Speech Unit Challenge.
