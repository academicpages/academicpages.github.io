---
permalink: [xinshengyang](https://githubyxs.github.io/)
title: "Xinsheng Yang"
author_profile: true
redirect_from: 
  - /about/I remain a visitor researcher with Visual Geometry Group (VGG) at Oxford
  - /about.html https://weidixie.github.io/
---

I'm generally interested in understanding how visual perception emerges. In particular, on topics:

learning visual representations from self-supervised training.

multi-modal co-training with visual apperance, motion, audio, textual description, etc.

artificial intelligence for science (AI4Science).!

 You can fork [this template](https://github.com/academicpages/academicpages.github.io) right now, modify the configuration and Markdown files, add your own PDFs and other content, and have your own site for free, with no ads!

A data-driven personal website
======
  I'm a first year undergraduate student from [School of LNTC]([https://icse.uestc.edu.cn/](https://www.lntu.edu.cn/)). My research interest includes computer vision, digital circuit design, deep learning, and spiking neuro network.

For those News::

- Dec 2025, 1 paper has been accepted by Nature. Congrats to all co-authors !

- Nov 2025, 1 paper has been accepted by 3DV 2026. Congrats to all co-authors !

- Nov 2025, 1 paper has been accepted by AAAI 2026. Congrats to all co-authors !

- Nov 2025, 1 paper has been accepted by NeurIPS 2025. Congrats to all co-authors !

- Sep 2025, 1 paper has been accepted by Nature Scientific Data. Congrats to all co-authors !

- Aug 2025, 1 paper has been accepted by Nature Communications. Congrats to all co-authors !

- Aug 2025, 1 paper has been accepted by Npj Digital Medicine (Nature Portfolio). Congrats to all co-authors !

- July 2025, 2 paper has been accepted by ACM MM 2025. Congrats to all co-authors !

- June 2025, 4 paper has been accepted by ICCV 2025. Congrats to all co-authors !

- June 2025, 1 paper has been accepted by Nature Communications. Congrats to all co-authors !

- May 2025, 1 papers have been accepted by MICCAI 2025. Congrats to all co-authors !

- Feb 2025, 3 papers have been accepted by CVPR 2025. Congrats to all co-authors !

- Jan 2025, 5 papers have been accepted by ICLR 2025. Congrats to all co-authors !

- Dec 2024, 1 paper has been accepted by Npj Digital Medicine (Nature Portfolio). Congrats to all co-authors !

- Dec 2024, 1 paper has been accepted by Communications Medicine. Congrats to all co-authors !

- Sep 2024, PMC-CLIP has been selected as final list of MICCAI Young Scientist Publication Impact Award

- Sep 2024, 1 paper has been accepted by NeurIPS 2024. Congrats to all co-authors !

- Sep 2024, 1 paper has been accepted by Nature Communications. Congrats to all co-authors !

- Sep 2024, 2 paper has been accepted by ACCV20 24. Congrats to all co-authors !

- Sep 2024, 3 paper has been accepted by EMNLP 2024. Congrats to all co-authors !

- July 2024, 1 paper has been accepted by ACM MM 2024. Congrats to all co-authors !

- July 2024, 1 paper has been accepted by Nature Communications. Congrats to all co-authors !

- July 2024, 5 papers have been accepted by ECCV 2024. Congrats to all co-authors !

- July 2024, 2 papers have been accepted by International Journal of Computer Vision. Congrats to all co-authors !

- Feb 2024, 6 papers have been accepted by CVPR 2024. Congrats to all co-authors !

- Feb 2024, 1 papers have been accepted by Journal of the American Medical Informatics Association. Congrats to all co-authors !

- Feb 2024, Talks on Multimodal Video Understanding, at Visual Geometry Group (VGG) at University of Oxford.

- Dec 2023, invited talks at AI+ Health Conference at Stanford University .

- Sep 2023, 2 papers have been accepted by NeurIPS 2023. Congrats to all co-authors !

- July 2023, 6 papers have been accepted by ICCV 2023. Congrats to all co-authors !

- June 2023, 1 paper has been accepted by Nature Communications. Congrats to all co-authors !

- June 2023, 1 paper have been accepted by MICCAI 2023. Congrats to all co-authors !

- June 2023, CVPR 2023 Tutorial: Object Localisation for Free, Going Beyond Self-supervised Learning.

May 2023, invited talks at CFAR Rising Star Lecture Series .
Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this template](https://github.com/academicpages/academicpages.github.io) by clicking the "Use this template" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](https://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section


To Prospective Student
------
Make sure you read this document before sending emails.

For PhD applicants, please contact me at least half a year prior to your application.



For more info
------
More info about configuring Academic Pages can be found in [the guide](https://academicpages.github.io/markdown/), the [growing wiki](https://github.com/academicpages/academicpages.github.io/wiki), and you can always [ask a question on GitHub](https://github.com/academicpages/academicpages.github.io/discussions). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
