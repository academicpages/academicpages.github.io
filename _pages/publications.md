---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my papers on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}


**[Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models](https://openreview.net/forum?id=cQWsTeTSkZ)** \
**Sanae Lotfi<sup>\*</sup>**, Yilun Kuang<sup>\*</sup>, Brandon Amos, Micah Goldblum, Marc Finzi, Andrew Gordon Wilson \
_ICML Workshop on Theoretical Foundations of Foundation Models, 2024_ \
**Oral Presentation** 
_Under conference review._ 

**[Non-Vacuous Generalization Bounds for Large Language Models](https://arxiv.org/abs/2312.17173)** \
**Sanae Lotfi<sup>\*</sup>**, Marc Finzi<sup>\*</sup>, Yilun Kuang<sup>\*</sup>, Tim G. J. Rudner, Micah Goldblum, Andrew Gordon Wilson \
_International Conference on Machine Learning (ICML), 2024_ \
[[arxiv](https://arxiv.org/abs/2312.17173), [code](https://github.com/Sanaelotfi/sublora-bounds-for-llms)]

**Mitigating Augmentation Bias with Input-Dependent Distributions over Augmentations** \
**Sanae Lotfi**, Tim G. J. Rudner, Brandon Amos, Andrew Gordon Wilson \
_Under review, soon on arxiv._ 

**[Bayesian Model Selection, the Marginal Likelihood, and Generalization (Extended Paper)](https://arxiv.org/abs/2202.11678)** \
**Sanae Lotfi**, Pavel Izmailov, Gregory Benton, Micah Goldblum, Andrew Gordon Wilson \
_Journal of Machine Learning Research (JMLR), 2023_ \
**Best Papers Track** \
[[arxiv](https://arxiv.org/pdf/2202.11678.pdf), [code](https://github.com/Sanaelotfi/Bayesian_model_comparison)]

**[PAC-Bayes Compression Bounds So Tight That They Can Explain Generalization](https://arxiv.org/abs/2211.13609)** \
**Sanae Lotfi<sup>\*</sup>**, Marc Finzi<sup>\*</sup>, Sanyam Kapoor<sup>\*</sup>, Andres Potapczynski<sup>\*</sup>, Micah Goldblum, Andrew Gordon Wilson \
_Neural Information Processing Systems (NeurIPS), 2022_ \
[[arxiv](https://arxiv.org/abs/2211.13609), [code](https://github.com/activatedgeek/tight-pac-bayes)]

**[Bayesian Model Selection, the Marginal Likelihood, and Generalization](https://arxiv.org/abs/2202.11678)** \
**Sanae Lotfi**, Pavel Izmailov, Gregory Benton, Micah Goldblum, Andrew Gordon Wilson \
_International Conference on Machine Learning (ICML), 2022_ \
**Long oral presentation, top 2% submissions** \
**Outstanding Paper Award** \
[[arxiv](https://arxiv.org/pdf/2202.11678.pdf), [code](https://github.com/Sanaelotfi/Bayesian_model_comparison), <a href="https://sanaelotfi.github.io/pdf/posters/LML_Poster_ICML_2022.pdf" target="_blank">poster</a>, [talk](https://slideslive.com/38983095/bayesian-model-selection-the-marginal-likelihood-and-generalization), <a href="https://sanaelotfi.github.io/pdf/slides/conference_presentations/LML_Sanae_Lotfi_ICML_2022.pdf" target="_blank">slides</a>]

**[Dangers of Bayesian Model Averaging under Covariate Shift](https://arxiv.org/abs/2106.11905)** \
Pavel Izmailov, Patrick Nicholson, **Sanae Lotfi**, Andrew Gordon Wilson \
_Neural Information Processing Systems (NeurIPS), 2021_ \
[[arxiv](https://arxiv.org/abs/2106.11905), [code](https://github.com/izmailovpavel/bnn_covariate_shift), <a href="https://sanaelotfi.github.io/pdf/posters/BMA_Dangers_Poster_NeurIPS_2021.pdf" target="_blank">poster</a>]

**[Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling](https://arxiv.org/abs/2102.13042)** \
Gregory W. Benton, Wesley J. Maddox, **Sanae Lotfi**, Andrew Gordon Wilson \
_International Conference on Machine Learning (ICML), 2021_ \
**Spotlight Presentation** \
[[arxiv](https://arxiv.org/abs/2102.13042), [code](https://github.com/g-benton/loss-surface-simplexes), <a href="https://sanaelotfi.github.io/pdf/slides/conference_presentations/Loss_Surface_Simplexes_ICML_2021.pdf" target="_blank">slides</a>]

**[Evaluating Approximate Inference in Bayesian Deep Learning](https://proceedings.mlr.press/v176/wilson22a/wilson22a.pdf)** \
Andrew Gordon Wilson, **Sanae Lotfi**, Sharad Vikram, Matthew D. Hoffman, Yarin Gal, Yingzhen Li, Melanie F. Pradier, Andrew Foong, Sebastian Farquhar, Pavel Izmailov \
_NeurIPS Competition and Demonstration Track, Proceedings of Machine Learning Research (PMLR), 2021_ \
[[plmr](https://proceedings.mlr.press/v176/wilson22a/wilson22a.pdf), [code](https://github.com/izmailovpavel/neurips_bdl_starter_kit), [website](https://izmailovpavel.github.io/neurips_bdl_competition/)]

**[Adaptive First-and Second-Order Algorithms for Large-Scale Machine Learning](https://arxiv.org/abs/2111.14761)** \
**Sanae Lotfi**, Tiphaine Bonniot de Ruisselet, Dominique Orban, Andrea Lodi \
_Annual Conference on Machine Learning, Optimization, and Data Science (LOD)_ \
**Oral Presentation**\
[[arxiv](https://arxiv.org/pdf/2111.14761.pdf)]

**[Stochastic Damped L-BFGS with Controlled Norm of the Hessian Approximation](https://arxiv.org/abs/2012.05783)**\
**Sanae Lotfi**, Tiphaine B. de Ruisselet, Dominique Orban, Andrea Lodi \
_SIAM Conference on Optimization, 2021_ \
**Oral Presentation** \
_NeurIPS Optimization for Machine Learning Workshop, 2020_ \
**Spotlight Presentation** \
[[arxiv](https://arxiv.org/abs/2012.05783)]

**[Stochastic First and Second Order Optimization Methods for Machine Learning](https://publications.polymtl.ca/5457/)** \
**Sanae Lotfi** \
_Master's Thesis, 2020_ \
**Best Thesis Award in Applied Mathematics at Polytechnique Montreal** \
Polytechnique Montreal

<sup>*</sup> denotes equal contribution. 
